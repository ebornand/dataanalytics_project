install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2021-08-24&limit=1000")
en_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2021-08-24&limit=1000")
ru_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=ru_all&date__gte=2021-08-24&limit=1000")
# data_json contains two lists: meta and objects. we need to convert the objects-list into a nice dataframe
# we need to loop through the objects list. each element in data_json$objects contains another list with all the data for one day
# we create a vector for each variable
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in de_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, i$happiness)
timeseries <- append(timeseries, i$timeseries)
}
#creating the english language data frame
data_de <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in en_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, i$happiness)
timeseries <- append(timeseries, i$timeseries)
}
#creating the german language data frame
data_en <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in ru_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, i$happiness)
timeseries <- append(timeseries, i$timeseries)
}
#creating the russian language data frame
data_ru <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
#creating a plot for the german language
plot_de <- ggplot(data_de, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_en <- ggplot(data_en, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_ru <- ggplot(data_ru, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
render_site()
render_site()
render_site()
render_site()
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in data_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.integer(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
# we now can create a clean dataframe with our sorted vectors, fabulous :)
data <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
ggplot(data, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
theme_light()
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in data_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
data <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
# as we can see, the latest entry is from 19.03.2020 -.-, we need to take a closer look at the hedonometer api to get the latest data
ggplot(data, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
theme_light()
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in de_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.Double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
install.packages("rjson")
install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2021-08-24&limit=1000")
en_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2021-08-24&limit=1000")
install.packages("rjson")
library("rmarkdown")
render_site()
render_site()
---
title: "Data Analytics Project"
description: |
Elea Bornand & Roman Alt
site: distill::distill_website
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
```
# Introduction
On <i>February, 24, 2022</i> Russia invaded Ukraine. The invasion represents a momentous escalation of the <i>Russo-Ukrainian War</i> that has been going on since 2014. The war mainly revolves around the status of strategically significant regions (e.g., Alfarsi, 2022).<br/><br/>
Since the invasion, over 4.1 million Ukrainian citizens have suddenly had to flee their home country into the unknown (as of April, 1, 2022; Global Conflict Tracker, 2022). People around the globe are moved by the horrifying circumstances Ukrainians are facing day-to-day. The <i>Russia-Ukraine Conflict</i> is all over the news and social media, e.g., Twitter.<br/><br/>
Twitter is a popular “online, global microblog and social networking service“ (Dodds et al., 2011) with <i>500 million tweets per day by 217 million daily active users</i> (tweeters; as of February, 21, 2022; Selected Company Metrics and Financials, 2022). But how do tweeters feel towards the matter they choose to address? To what extent do their tweets indicate sentiments, e.g., happiness? What words do they use to express their thoughts on the matter?<br/><br/>
Quantifying happiness is what the <i>hedonometer (hedonometer.org)</i> aims at: It meters (and visualizes) Twitter users’ “hedonistic“ (positive) emotions (i.e., happiness in this case). Like other sentiment analysis techniques, it assigns sentiment (happiness) scores (ranging continuously from <i>(1) least</i> to <i>(9) most happy</i>) to textual data based on the words included. To do so, it is fed with wordlists corresponding to the language the textual data is in. Wordlists related to the hedonometer currently exist in ten different languages, e.g., English, German, Russian, and Ukrainian.<br/><br/>
The hedonometer computes the weighted average happiness of texts through the following equation (Qiao & Jiang, 2022):
Figure 1: The equation the hedonometer computes the weighted average happiness score through (Qiao & Jiang, 2022).
–      wi: word in the text
–      fi: frequency of word
–      N: number of unique words
–      havg: average happiness
–      havg(T): average happiness of the whole text
–      havg(wi): average happiness of a word
–      pi: normalized frequency
Some of the hedonometer’s advantages are:<br/><br/>
–      It is capable of processing <i>large, real-time</i> textual data rapidly. This enables to gain large-scale insights into social phenomena on (Dodds & Danforth, 2009; Johnson & Alluri, 2016).
–      Unlike surveys, it does not depend on people’s self-reports of their emotional states (Dodds et al., 2011).
–      Its ways of processing data are transparent, therefore their improvement is not restricted to the development team (Dodds & Danforth, 2009).
On February, 24 and the days following, a <i>dip</i> in all languages’ average happiness scores can be noticed. However, shortly after, the scores normalize again. This could be due to a <i>habituation effect</i>, similar to the one regarding the COVID-19 pandemic that that has been observed by Dan and Brosius (2021).<br/><br/>
We therefore are interested in finding answers to the following <i>research question: How fast do average happiness scores of Twitter users tweeting in different languages normalize after February, 24 (i.e., beginning of the Russia-Ukraine Conflict; compared to their average happiness scores before February, 24)?</i><br/><br/>
What motivates us to work towards answering our research question?
–      Since it revolves around an ongoing conflict, it is highly topical. The data is newly collected.
–      Twitter is a widely used social networking service (Dodds et al., 2011; Selected Company Metrics and Financials, 2022).
–      Our motivation for focusing on the topic of sentiment analyses: expand what we have theoretically learnt about them in the course of a seminar held by the University’s Human-Computer Interaction department in the fall semester 2021.
More information:
–      On the hedonometer in general: https://hedonometer.org/timeseries/en_all/?from=2020-10-06&to=2022-04-05
–      On the wordlists used for the hedonometer (e.g., German): https://hedonometer.org/words/labMT-de-v2/
–      On the hedonometer’s data: https://hedonometer.org/api.html
Countries in which languages included in the “hedonometrics“ are officially spoken (in alphabetical order; Infoplease, 2022):
–  	German: Austria; Belgium; Germany; Italy; Liechtenstein; Luxembourg; Switzerland
–      English (third most widely spoken language): Antigua and Barbuda; Barbados; Belize; Botswana; Burundi; Cameroon; Canada; Cape Verde; Dominica; Eritrea; Eswatini; Fiji; Grenada; Guyana; Ireland; Kenya; Kiribati; Lesotho; Liberia; Malawi; Malta; Namibia; New Zealand; Nigeria; Pakistan; Palau; Palestinian State; Papua New Guinea; Philippines; Rwanda; Samoa; Seychelles; Sierra Leone; Singapore; Solomon Islands; South Africa; South Sudan; Sudan; Tanzania; Tonga; Trinidad and Tobago; Tuvalu; Uganda; United Kingdom; United States; Vanuatu; Zambia; Zimbabwe
–      Russian (eighth most widely spoken language): Belarus; Kazakhstan; Kyrgyzstan; Russia
–      Ukrainian: Ukraine
–      Spanish (second most widely spoken language): Argentina; Bolivia; Chile; Colombia; Costa Rica; Cuba; Dominican Republic; East Timor; Ecuador; El Salvador; Equatorial Guinea; Guatemala; Honduras; Mexico; Micronesia; Nicaragua; Panama; Paraguay; Peru; Spain; Uruguay; Venezuela
–      Portuguese (seventh most widely spoken language): Angola; Brazil; Equatorial Guinea; Guinea-Bissau; Mozambique; Myanmar; Portugal; Democratic Republic of São Tomé and Príncipe
–      French: Belgium; Benin; Burkina Faso; Burundi; Cameroon; Canada; Cape Verde; Central African Republic; Chad; Comoros; Democratic Republic of the Congo; Republic of Congo; Côte d’Ivoire; Djibouti; Equatorial Guinea; France; Gabon; Gambia; Guinea; Haiti; Luxembourg; Madagascar; Mali; Monaco; Niger; Rwanda; Senegal; Seychelles; Switzerland; Togo; Vanuatu
–      Chinese: China; Taiwan
–      Korean: North Korea; South Korea
–      Arabic (fifth most widely spoken language): Algeria; Bahrain; Chad; Comoros; Djibouti; Egypt; Eritrea; Iraq; Jordan; Kuwait; Lebanon; Libya; Mauritania; Morocco; Oman; Qatar; Saudi Arabia; Somalia; Sudan; Syria; Tunisia; United Arab Emirates; Yemen
References
–      Alfarsi, H. (2022). https://www.profolus.com/topics/causes-of-the-russia-ukraine-conflict-an-explainer/ [04.01.2022]
–  	Dan, V., & Brosius, H. B. (2021). The onset of habituation effects: Predicting fluctuations in news use during the COVID-19 pandemic by disease occurrence. European Journal of Health Communication, 2(3), 44-61. https://doi.org/10.47368/ejhc.2021.303
–      Dodds, P. S., Harris, K. D., Kloumann, I. M., Bliss, C. A., & Danforth, C. M. (2011). Temporal patterns of happiness and information in a global social network: Hedonometrics and Twitter. PloS one, 6(12), e26752. https://doi.org/10.1371/journal.pone.0026752
–  	Dodds, P. S., & Danforth, C. M. (2010). Measuring the happiness of large-scale written expression: Songs, blogs, and presidents. Journal of happiness studies, 11(4), 441-456. https://doi.org/10.1007/s10902-009-9150-9
–  	Global Conflict Tracker (2022). https://www.cfr.org/global-conflict-tracker/conflict/conflict-ukraine [04.01.2022]
–  	Infoplease (2022). https://www.infoplease.com/world/countries/languages-spoken-in-each-country-of-the-world [04.01.2022]
–      Johnson, B., & Alluri, A. (2022). If you’re happy and you know it, write a tweet. http://www.marketplace.org/2015/02/10/tech/if-youre-happy-and-you-know-it-write-tweet [04.01.2022]
–  	Qiao, F., & Jiang, K. (2021). Attitudes Towards Global Warming on Twitter: A Hedonometer-Appraisal Analysis. Journal of Global Information Management (JGIM), 30(7), 1-20. https://doi.org/10.4018/JGIM.296708
library
# Data
some Infos about our Data, where we got it from and how it is built. (different languages etc.)
# Method
how are we going to use that data. what variables are important, do we have a model to fit to the data etc.
# Results
At the moment we can show the development of happiness over time for three language-groups on Twitter, namely German, English and Russian.
```{r echo=FALSE, eval=FALSE}
install.packages("rjson")
install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2021-08-24&limit=1000")
en_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2021-08-24&limit=1000")
ru_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=ru_all&date__gte=2021-08-24&limit=1000")
# data_json contains two lists: meta and objects. we need to convert the objects-list into a nice dataframe
# we need to loop through the objects list. each element in data_json$objects contains another list with all the data for one day
# we create a vector for each variable
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in de_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the english language data frame
data_de <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in en_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the german language data frame
data_en <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in ru_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the russian language data frame
data_ru <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
#creating a plot for the german language
plot_de <- ggplot(data_de, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_en <- ggplot(data_en, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_ru <- ggplot(data_ru, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
```
### Development of Happiness over Time for german Twitter:
```{r}
plot_de
```
### Development of Happiness over Time for english Twitter:
```{r}
plot_en
```
### Development of Happiness over Time for russian Twitter:
```{r}
plot_ru
```
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
plot_de
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
install.packages("rjson")
library("rjson")
install.packages("rjson")
install.packages("rmarkdown")
library(rmarkdown)
render_site()
install.packages("distill")
render_site()
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
install.packages("rjson")
install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_habit_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2022-02-24&limit=1000")
de_base_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2022-01-25&limit=31")
data_de_habit <- createHedonDataFrame(de_habit_json)
source("code/JSON_handler.R")
data_de_habit <- createHedonDataFrame(de_habit_json)
data_de_habit <- function.createHedonDataFrame(de_habit_json)
plot_de <- ggplot(data_de_habit, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
plot_de
render_site()
source("code/plotter.R")
#creating a plot for the german language
plot_de <- function.basic_plott(data_de_habit)
#creating a plot for the german language
plot_de <- function.basic_plot(data_de_habit)
plot_de
data_de_habit <- function.createHedonDataFrame(de_habit_json)
data_de_base <- function.createHedonDataFrame(de_base_json)
#creating a plot for the german language
plot_de_habit <- function.basic_plot(data_de_habit)
plot_de_base <- function.basic_plot(data_de_base)
plot_de_habit
plot_de_base
de_base_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2022-01-24&limit=31")
data_de_base <- function.createHedonDataFrame(de_base_json)
plot_de_base <- function.basic_plot(data_de_base)
plot_de_base
render_site()
render_site()
data <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/Dataflow")
library("rjson")
data <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/Dataflow")
install.packages("imfr")
library("imfr")
imf_ids(return_raw = FALSE, times = 3)
data <- imf_ids(return_raw = FALSE, times = 3)
data
data$database_id
data_ids <- data$database_id
data_DOTs = c()
for (i in data_ids) {
if(grepl("DOT", i, fixed = TRUE)) {
data_DOTs.append(i)
}
}
for (i in data_ids) {
if(grepl("DOT", i, fixed = TRUE)) {
data_DOTs <- append(data_DOTs, i)
}
}
data_DOTs
library("rjson")
DOT_2021Q1 <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/DataStructure/DOT_2021Q1")
DOT_2021Q1
imf_codes()
imf_codes("DOT")
export_uk_de <- imf_ids(database_id = "DOT", country = c("UA", "DE"), return_raw = FALSE, time = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("UA", "DE"), return_raw = FALSE, time = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("UA", "DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(return_raw = FALSE, times = 3)
View(DOT_2021Q1)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), indicator = "EREER_IX",return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT_2021Q1", country = c("UA", "DE"), indicator = "EREER_IX",return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), indicator = "TXG_FOB_USD", return_raw = TRUE, times = 3)
data <- export_uk_de
data$CompactData$DataSet$Series
data_df <- data$CompactData$DataSet$Series
names(data_df)
View(data_df)
View(data_df[[7]][[1]])
imf_data?
?imf_Data$
?imf_Data
??imd_data
??imf_data
imf_codelist(database_id = "DOT". return_raw = FALSE, times = 3)
imf_codelist(database_id = "DOT", return_raw = FALSE, times = 3)
imf_codes(codelist = "CL_INDICATOR_DOT")
#exports from Ukraine to Germany:
export_FOB_Ukr$CompactData$DataSet$Series
export_FOB_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TXG_FOB_USD", return_raw = TRUE, times = 3)
import_CIF_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TMG_CIF_USD", return_raw = TRUE, times = 3)
trade_balance_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TBG_USD", return_raw = TRUE, times = 3)
#exports from Ukraine to Germany:
wtf <- export_FOB_Ukr$CompactData$DataSet$Series
wtf
View(wtf)
View(wtf)
names(wtf)
?wtf$@FREQ
?wtf$`@FREQ`
??wtf$`@FREQ`
??wtf$@FREQ
wtf$`@FREQ`
exports_ukr <- export_FOB_Ukr$CompactData$DataSet$Series
imports_ukr <- import_CIF_Ukr$CompactData$DataSet$Series
tb_ukr <- trade_balance_Ukr$CompactData$DataSet$Series
exports_ukr_de <- exports_ukr[exports_ukr$`@COUNTERPART_AREA` == "DE"]
exports_ukr_de <- exports_ukr[exports_ukr$COUNTERPART_AREA == "DE"]
exports_ukr$COUNTERPART_AREA
colnames(exports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
names(export_ukr)
names(exports$_ukr)
names(exports_ukr)
names(imports_ukr)
names(tb_ukr)
colnames(exports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
colnames(imports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
colnames(tb_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE"]
View(export_uk_de)
View(exports_ukr)
exports_ukr$counterpart_area
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE"]
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE",]
exports_ukr_de
View(exports_ukr_de)
View(exports_ukr_de[[7]][[481]])
View(exports_ukr_de[[7]][[481]])
install.packages("dplyr")
library("dplyr")
exports_ukr_de <- filter(exports_ukr, counterpart_area == "DE" & time_format == "A")
exports_ukr_de
View(exports_ukr)
exports_ukr_de <- filter(exports_ukr, counterpart_area == "DE" & frequency == "A")
exports_ukr_de
exports_ukr_de$obs
install.packages("ggmap")
library("ggmap")
# calculate distance between two place names
arena_dist <- mapdist(from = "Madison Square Garden New York, NY", to = "The Palace of Auburn Hills Auburn Hills, MI")
# output distance in miles
arena_dist$miles
# output "distance" in minutes
arena_dist$minutes
?register_google
showing_key()
ggmap_show_api_key()
ggmap_hide_api_key()
library("rjson")
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew&destinations=London&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance
View(df_distance)
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew, Ukraine&destinations=London, United Kigndom&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew, Ukraine&destinations=London, United Kigndom&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_geocode <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Kiew&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
df_geocode
View(df_geocode)
df_geocode$locations$referenceposition
df_geocode$locations[1]$referenceposition
df_geocode$locations
df_geocode$locations[1]
names(df_geocode$locations[1])
names(df_geocode$locations)
df_geocode_location <- df_geocode$locations[1]
df_geocode_location
View(df_geocode)
coordinates_kiew <- c(df_geocode$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
df_geocode_kiew <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Kiew&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
df_geocode_berlin <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Berlin&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew[1]
coordinates_kiew[2]
coordinates_kiew[0]
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=" + coordinates_kiew[1] + ", " + coordinates_kiew[2] + "&destinations=" + coordinates_berlin[1] + ", " + coordinates_berlin[2] + "&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance <- fromJSON(file = cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
df_distance <- fromJSON(file = cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB',))
url <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1], ', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url
url <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url
url_test
url_test <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url_test
?cat
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ',', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ',', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
df_distance <- fromJSON(file = url_test)
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB', sep = ""))
url_test
df_distance <- fromJSON(file = url_test)
df_distance
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode_kiew$locations[[1]]$referencePosition$longitude)
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode_berlin$locations[[1]]$referencePosition$longitude)
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB', sep = ""))
df_distance <- fromJSON(file = url_test)
df_distance
countries_capitals <- fromJSON(file = "https://countriesnow.space/api/v0.1/countries/capital")
View(countries_capitals)
countries_capitals <- countries_capitals$data
View(countries_capitals)
