–  	German: Austria; Belgium; Germany; Italy; Liechtenstein; Luxembourg; Switzerland
–      English (third most widely spoken language): Antigua and Barbuda; Barbados; Belize; Botswana; Burundi; Cameroon; Canada; Cape Verde; Dominica; Eritrea; Eswatini; Fiji; Grenada; Guyana; Ireland; Kenya; Kiribati; Lesotho; Liberia; Malawi; Malta; Namibia; New Zealand; Nigeria; Pakistan; Palau; Palestinian State; Papua New Guinea; Philippines; Rwanda; Samoa; Seychelles; Sierra Leone; Singapore; Solomon Islands; South Africa; South Sudan; Sudan; Tanzania; Tonga; Trinidad and Tobago; Tuvalu; Uganda; United Kingdom; United States; Vanuatu; Zambia; Zimbabwe
–      Russian (eighth most widely spoken language): Belarus; Kazakhstan; Kyrgyzstan; Russia
–      Ukrainian: Ukraine
–      Spanish (second most widely spoken language): Argentina; Bolivia; Chile; Colombia; Costa Rica; Cuba; Dominican Republic; East Timor; Ecuador; El Salvador; Equatorial Guinea; Guatemala; Honduras; Mexico; Micronesia; Nicaragua; Panama; Paraguay; Peru; Spain; Uruguay; Venezuela
–      Portuguese (seventh most widely spoken language): Angola; Brazil; Equatorial Guinea; Guinea-Bissau; Mozambique; Myanmar; Portugal; Democratic Republic of São Tomé and Príncipe
–      French: Belgium; Benin; Burkina Faso; Burundi; Cameroon; Canada; Cape Verde; Central African Republic; Chad; Comoros; Democratic Republic of the Congo; Republic of Congo; Côte d’Ivoire; Djibouti; Equatorial Guinea; France; Gabon; Gambia; Guinea; Haiti; Luxembourg; Madagascar; Mali; Monaco; Niger; Rwanda; Senegal; Seychelles; Switzerland; Togo; Vanuatu
–      Chinese: China; Taiwan
–      Korean: North Korea; South Korea
–      Arabic (fifth most widely spoken language): Algeria; Bahrain; Chad; Comoros; Djibouti; Egypt; Eritrea; Iraq; Jordan; Kuwait; Lebanon; Libya; Mauritania; Morocco; Oman; Qatar; Saudi Arabia; Somalia; Sudan; Syria; Tunisia; United Arab Emirates; Yemen
References
–      Alfarsi, H. (2022). https://www.profolus.com/topics/causes-of-the-russia-ukraine-conflict-an-explainer/ [04.01.2022]
–  	Dan, V., & Brosius, H. B. (2021). The onset of habituation effects: Predicting fluctuations in news use during the COVID-19 pandemic by disease occurrence. European Journal of Health Communication, 2(3), 44-61. https://doi.org/10.47368/ejhc.2021.303
–      Dodds, P. S., Harris, K. D., Kloumann, I. M., Bliss, C. A., & Danforth, C. M. (2011). Temporal patterns of happiness and information in a global social network: Hedonometrics and Twitter. PloS one, 6(12), e26752. https://doi.org/10.1371/journal.pone.0026752
–  	Dodds, P. S., & Danforth, C. M. (2010). Measuring the happiness of large-scale written expression: Songs, blogs, and presidents. Journal of happiness studies, 11(4), 441-456. https://doi.org/10.1007/s10902-009-9150-9
–  	Global Conflict Tracker (2022). https://www.cfr.org/global-conflict-tracker/conflict/conflict-ukraine [04.01.2022]
–  	Infoplease (2022). https://www.infoplease.com/world/countries/languages-spoken-in-each-country-of-the-world [04.01.2022]
–      Johnson, B., & Alluri, A. (2022). If you’re happy and you know it, write a tweet. http://www.marketplace.org/2015/02/10/tech/if-youre-happy-and-you-know-it-write-tweet [04.01.2022]
–  	Qiao, F., & Jiang, K. (2021). Attitudes Towards Global Warming on Twitter: A Hedonometer-Appraisal Analysis. Journal of Global Information Management (JGIM), 30(7), 1-20. https://doi.org/10.4018/JGIM.296708
library
# Data
some Infos about our Data, where we got it from and how it is built. (different languages etc.)
# Method
how are we going to use that data. what variables are important, do we have a model to fit to the data etc.
# Results
At the moment we can show the development of happiness over time for three language-groups on Twitter, namely German, English and Russian.
```{r echo=FALSE, eval=FALSE}
install.packages("rjson")
install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2021-08-24&limit=1000")
en_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2021-08-24&limit=1000")
ru_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=ru_all&date__gte=2021-08-24&limit=1000")
# data_json contains two lists: meta and objects. we need to convert the objects-list into a nice dataframe
# we need to loop through the objects list. each element in data_json$objects contains another list with all the data for one day
# we create a vector for each variable
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
# we loop through each element in data_json$objects and sort the parameters into their respective vector
for (i in de_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the english language data frame
data_de <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in en_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the german language data frame
data_en <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
date <- c()
frequency <- c()
happiness <- c()
timeseries <- c()
for (i in ru_json$objects) {
date <- append(date, as.Date(i$date))
frequency <- append(frequency, i$frequency)
happiness <- append(happiness, as.double(i$happiness))
timeseries <- append(timeseries, i$timeseries)
}
#creating the russian language data frame
data_ru <- data.frame(date = date, frequency = frequency, happiness = happiness, timeseries = timeseries)
#creating a plot for the german language
plot_de <- ggplot(data_de, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_en <- ggplot(data_en, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
#creating a plot for the english language
plot_ru <- ggplot(data_ru, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
```
### Development of Happiness over Time for german Twitter:
```{r}
plot_de
```
### Development of Happiness over Time for english Twitter:
```{r}
plot_en
```
### Development of Happiness over Time for russian Twitter:
```{r}
plot_ru
```
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
plot_de
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
install.packages("rjson")
library("rjson")
install.packages("rjson")
install.packages("rmarkdown")
library(rmarkdown)
render_site()
install.packages("distill")
render_site()
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
install.packages("rjson")
install.packages("ggplot2")
library("rjson")
library("ggplot2")
de_habit_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2022-02-24&limit=1000")
de_base_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2022-01-25&limit=31")
data_de_habit <- createHedonDataFrame(de_habit_json)
source("code/JSON_handler.R")
data_de_habit <- createHedonDataFrame(de_habit_json)
data_de_habit <- function.createHedonDataFrame(de_habit_json)
plot_de <- ggplot(data_de_habit, aes(x = date, y = happiness, group = 1)) +
geom_line() +
geom_point() +
geom_smooth() +
theme_light()
plot_de
render_site()
source("code/plotter.R")
#creating a plot for the german language
plot_de <- function.basic_plott(data_de_habit)
#creating a plot for the german language
plot_de <- function.basic_plot(data_de_habit)
plot_de
data_de_habit <- function.createHedonDataFrame(de_habit_json)
data_de_base <- function.createHedonDataFrame(de_base_json)
#creating a plot for the german language
plot_de_habit <- function.basic_plot(data_de_habit)
plot_de_base <- function.basic_plot(data_de_base)
plot_de_habit
plot_de_base
de_base_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=en_all&date__gte=2022-01-24&limit=31")
data_de_base <- function.createHedonDataFrame(de_base_json)
plot_de_base <- function.basic_plot(data_de_base)
plot_de_base
render_site()
render_site()
data <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/Dataflow")
library("rjson")
data <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/Dataflow")
install.packages("imfr")
library("imfr")
imf_ids(return_raw = FALSE, times = 3)
data <- imf_ids(return_raw = FALSE, times = 3)
data
data$database_id
data_ids <- data$database_id
data_DOTs = c()
for (i in data_ids) {
if(grepl("DOT", i, fixed = TRUE)) {
data_DOTs.append(i)
}
}
for (i in data_ids) {
if(grepl("DOT", i, fixed = TRUE)) {
data_DOTs <- append(data_DOTs, i)
}
}
data_DOTs
library("rjson")
DOT_2021Q1 <- fromJSON(file = "http://dataservices.imf.org/REST/SDMX_JSON.svc/DataStructure/DOT_2021Q1")
DOT_2021Q1
imf_codes()
imf_codes("DOT")
export_uk_de <- imf_ids(database_id = "DOT", country = c("UA", "DE"), return_raw = FALSE, time = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("UA", "DE"), return_raw = FALSE, time = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("UA", "DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", country = c("DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(database_id = "DOT_2021Q1", return_raw = FALSE, times = 3)
export_uk_de <- imf_ids(return_raw = FALSE, times = 3)
View(DOT_2021Q1)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), indicator = "EREER_IX",return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT_2021Q1", country = c("UA", "DE"), indicator = "EREER_IX",return_raw = FALSE, times = 3)
export_uk_de <- imf_data(database_id = "DOT", country = c("UA", "DE"), indicator = "TXG_FOB_USD", return_raw = TRUE, times = 3)
data <- export_uk_de
data$CompactData$DataSet$Series
data_df <- data$CompactData$DataSet$Series
names(data_df)
View(data_df)
View(data_df[[7]][[1]])
imf_data?
?imf_Data$
?imf_Data
??imd_data
??imf_data
imf_codelist(database_id = "DOT". return_raw = FALSE, times = 3)
imf_codelist(database_id = "DOT", return_raw = FALSE, times = 3)
imf_codes(codelist = "CL_INDICATOR_DOT")
#exports from Ukraine to Germany:
export_FOB_Ukr$CompactData$DataSet$Series
export_FOB_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TXG_FOB_USD", return_raw = TRUE, times = 3)
import_CIF_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TMG_CIF_USD", return_raw = TRUE, times = 3)
trade_balance_Ukr <- imf_data(database_id = "DOT", country = "UA", indicator = "TBG_USD", return_raw = TRUE, times = 3)
#exports from Ukraine to Germany:
wtf <- export_FOB_Ukr$CompactData$DataSet$Series
wtf
View(wtf)
View(wtf)
names(wtf)
?wtf$@FREQ
?wtf$`@FREQ`
??wtf$`@FREQ`
??wtf$@FREQ
wtf$`@FREQ`
exports_ukr <- export_FOB_Ukr$CompactData$DataSet$Series
imports_ukr <- import_CIF_Ukr$CompactData$DataSet$Series
tb_ukr <- trade_balance_Ukr$CompactData$DataSet$Series
exports_ukr_de <- exports_ukr[exports_ukr$`@COUNTERPART_AREA` == "DE"]
exports_ukr_de <- exports_ukr[exports_ukr$COUNTERPART_AREA == "DE"]
exports_ukr$COUNTERPART_AREA
colnames(exports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
names(export_ukr)
names(exports$_ukr)
names(exports_ukr)
names(imports_ukr)
names(tb_ukr)
colnames(exports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
colnames(imports_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
colnames(tb_ukr) <- c("frequency", "ref_area", "indicator", "counterpart_area", "unit_mult", "time_format", "obs")
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE"]
View(export_uk_de)
View(exports_ukr)
exports_ukr$counterpart_area
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE"]
exports_ukr_de <- exports_ukr[exports_ukr$counterpart_area == "DE",]
exports_ukr_de
View(exports_ukr_de)
View(exports_ukr_de[[7]][[481]])
View(exports_ukr_de[[7]][[481]])
install.packages("dplyr")
library("dplyr")
exports_ukr_de <- filter(exports_ukr, counterpart_area == "DE" & time_format == "A")
exports_ukr_de
View(exports_ukr)
exports_ukr_de <- filter(exports_ukr, counterpart_area == "DE" & frequency == "A")
exports_ukr_de
exports_ukr_de$obs
install.packages("ggmap")
library("ggmap")
# calculate distance between two place names
arena_dist <- mapdist(from = "Madison Square Garden New York, NY", to = "The Palace of Auburn Hills Auburn Hills, MI")
# output distance in miles
arena_dist$miles
# output "distance" in minutes
arena_dist$minutes
?register_google
showing_key()
ggmap_show_api_key()
ggmap_hide_api_key()
library("rjson")
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew&destinations=London&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance
View(df_distance)
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew, Ukraine&destinations=London, United Kigndom&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=Kiew, Ukraine&destinations=London, United Kigndom&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_geocode <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Kiew&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
df_geocode
View(df_geocode)
df_geocode$locations$referenceposition
df_geocode$locations[1]$referenceposition
df_geocode$locations
df_geocode$locations[1]
names(df_geocode$locations[1])
names(df_geocode$locations)
df_geocode_location <- df_geocode$locations[1]
df_geocode_location
View(df_geocode)
coordinates_kiew <- c(df_geocode$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
df_geocode_kiew <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Kiew&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
df_geocode_berlin <- fromJSON(file = "https://api.myptv.com/geocoding/v1/locations/by-text?searchText=Berlin&apiKey=NTA1NjJmNjQ4MGNkNDc0MmFlM2IzMjJiZGM3ZDI1ZjU6MGM1NzUyZTgtMzE3ZC00Nzg0LWJiODQtMTY5OGJkNzQxYTlj")
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew[1]
coordinates_kiew[2]
coordinates_kiew[0]
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
df_distance <- fromJSON(file = "https://api.distancematrix.ai/maps/api/distancematrix/json?origins=" + coordinates_kiew[1] + ", " + coordinates_kiew[2] + "&destinations=" + coordinates_berlin[1] + ", " + coordinates_berlin[2] + "&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB")
df_distance <- fromJSON(file = cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
df_distance <- fromJSON(file = cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB',))
url <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1], ', ',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],', ',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url
url <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url
url_test
url_test <- cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB')
url_test
?cat
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ', ', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ', ', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=', coordinates_kiew[1], ',', coordinates_kiew[2], '&destinations=', coordinates_berlin[1], ',', coordinates_berlin[2], '&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB'))
url_test
df_distance <- fromJSON(file = url_test)
url_test
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB', sep = ""))
url_test
df_distance <- fromJSON(file = url_test)
df_distance
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode$locations[[1]]$referencePosition$longitude)
coordinates_kiew <- c(df_geocode_kiew$locations[[1]]$referencePosition$latitude, df_geocode_kiew$locations[[1]]$referencePosition$longitude)
coordinates_berlin <- c(df_geocode_berlin$locations[[1]]$referencePosition$latitude, df_geocode_berlin$locations[[1]]$referencePosition$longitude)
url_test <- capture.output(cat('https://api.distancematrix.ai/maps/api/distancematrix/json?origins=',coordinates_kiew[1],',',coordinates_kiew[2],'&destinations=',coordinates_berlin[1],',',coordinates_berlin[2],'&key=PLYEuZwg3IgiJPUOvpIS91prJ7jLB', sep = ""))
df_distance <- fromJSON(file = url_test)
df_distance
countries_capitals <- fromJSON(file = "https://countriesnow.space/api/v0.1/countries/capital")
View(countries_capitals)
countries_capitals <- countries_capitals$data
View(countries_capitals)
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
install.packages("rjson")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
library("rjson")
library("ggplot2")
source("code/JSON_handler.R")
source("code/plotter.R")
de_habit_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2022-02-24&limit=1000")
de_base_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2022-01-24&limit=31")
data_de_habit <- function.createHedonDataFrame(de_habit_json)
data_de_base <- function.createHedonDataFrame(de_base_json)
#creating a plot for the german language
plot_de_habit <- function.basic_plot(data_de_habit)
plot_de_base <- function.basic_plot(data_de_base)
hedonometer_data
hedonometer_data <- data.frame(data_language, data_baseline_mean, data_baseline_sd, data_reactivity, data_habituation)
install.packages("rjson")
library("rjson")
source("code/JSON_handler.R")
languages_iso2 <- c("en", "de", "ru", "es", "pt", "fr", "ar", "id", "ko")
data_hedon_total <- list()
for (l in languages_iso2) {
habit_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-02-24&limit=1000", sep = "")))
base_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-01-24&limit=31", sep = "")))
base_data <- function.createHedonDataFrame(base_json_data)
habit_data <- function.createHedonDataFrame(habit_json_data)
data_hedon_total[[length(data_hedon_total)+1]] <- list(l, base_data, habit_data)
}
#creating final data frame
data_language <- c()
data_baseline_mean <- c()
data_baseline_sd <- c()
data_reactivity <- c()
data_habituation <- c()
for (d in data_hedon_total) {
language <- d[[1]]
base <- d[[2]]
habit <- d[[3]]
data_language <- append(data_language, language)
data_baseline_mean <- append(data_baseline_mean, mean(base$happiness))
data_baseline_sd <- append(data_baseline_sd, sd(base$happiness))
data_reactivity <- append(data_reactivity, (mean(base$happiness) - habit$happiness[1]))
data_habituation <-append(data_habituation, coef(lm(habit$happiness ~ habit$date, data = habit))[2])
}
hedonometer_data <- data.frame(data_language, data_baseline_mean, data_baseline_sd, data_reactivity, data_habituation)
install.packages("rjson")
library("rjson")
source("code/JSON_handler.R")
languages_iso2 <- c("en", "de", "ru", "es", "pt", "fr", "ar", "id", "ko")
data_hedon_total <- list()
for (l in languages_iso2) {
habit_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-02-24&limit=1000", sep = "")))
base_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-01-24&limit=31", sep = "")))
base_data <- function.createHedonDataFrame(base_json_data)
habit_data <- function.createHedonDataFrame(habit_json_data)
data_hedon_total[[length(data_hedon_total)+1]] <- list(l, base_data, habit_data)
}
#creating final data frame
data_language <- c()
data_baseline_mean <- c()
data_baseline_sd <- c()
data_reactivity <- c()
data_habituation <- c()
for (d in data_hedon_total) {
language <- d[[1]]
base <- d[[2]]
habit <- d[[3]]
data_language <- append(data_language, language)
data_baseline_mean <- append(data_baseline_mean, mean(base$happiness))
data_baseline_sd <- append(data_baseline_sd, sd(base$happiness))
data_reactivity <- append(data_reactivity, (mean(base$happiness) - habit$happiness[1]))
data_habituation <-append(data_habituation, coef(lm(habit$happiness ~ habit$date, data = habit))[2])
}
hedonometer_data <- data.frame(data_language, data_baseline_mean, data_baseline_sd, data_reactivity, data_habituation)
hedonometer_data
plot_de_habit
library("rmarkdown")
render_site
render_site()
install.packages("lemon")
library("lemon")
head(hedonometer_data)
render_site()
knit_print.data.frame <- lemon_print
render_site()
print(hedonometer_data)
render_site()
hedonometer_data
render_site()
languages_iso2 <- c("en", "de", "ru", "uk", "es", "pt", "fr", "ar", "id", "ko")
data_hedon_total <- list()
for (l in languages_iso2) {
habit_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-02-24&limit=1000", sep = "")))
base_json_data <- fromJSON(file = capture.output(cat("http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=",
l, "_all&date__gte=2022-01-24&limit=31", sep = "")))
base_data <- function.createHedonDataFrame(base_json_data)
habit_data <- function.createHedonDataFrame(habit_json_data)
data_hedon_total[[length(data_hedon_total)+1]] <- list(l, base_data, habit_data)
}
#creating final data frame
data_language <- c()
data_baseline_mean <- c()
data_baseline_sd <- c()
data_reactivity <- c()
data_habituation <- c()
for (d in data_hedon_total) {
language <- d[[1]]
base <- d[[2]]
habit <- d[[3]]
data_language <- append(data_language, language)
data_baseline_mean <- append(data_baseline_mean, mean(base$happiness))
data_baseline_sd <- append(data_baseline_sd, sd(base$happiness))
data_reactivity <- append(data_reactivity, (mean(base$happiness) - habit$happiness[1]))
data_habituation <-append(data_habituation, coef(lm(habit$happiness ~ habit$date, data = habit))[2])
}
hedonometer_data <- data.frame(data_language, data_baseline_mean, data_baseline_sd, data_reactivity, data_habituation)
hedonometer_data
render_site()
library("rmarkdown")
render_site()
library("rmarkdown")
render_site()
---
title: "Data Analytics Project"
description: |
Elea Bornand & Roman Alt
site: distill::distill_website
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html
```
```{r results="asis"}
cat(readLines('text/home.txt'), sep = '\n')
```
# Results
At the moment we can show the development of happiness aswell as a Baseline Graph before the 24.2.2022 for German Twitter
Also we already have the processed Data from hedonometer.org, aswell as Language, Capital and Iso2 code for all relevant countries.
```{r echo=FALSE, eval=FALSE}
install.packages("rjson")
install.packages("ggplot2")
install.packages("lemon")
library("rjson")
library("lemon")
knit_print.data.frame <- lemon_print
source("code/JSON_handler.R")
source("code/plotter.R")
de_habit_json <- fromJSON(file = "http://hedonometer.org/api/v1/happiness/?format=json&timeseries__title=de_all&date__gte=2022-02-24&limit=1000")
